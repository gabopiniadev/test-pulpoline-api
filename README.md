# Test Pulpoline API üöÄ

Un servicio web en Go que procesa texto usando inteligencia artificial. Permite enviar preguntas o textos y recibir respuestas generadas por IA, todo manejado de forma concurrente y eficiente.

## ¬øQu√© hace este proyecto?

Imag√≠nate que tienes un asistente virtual que responde preguntas. Este servicio hace exactamente eso: recibes texto (como "¬øQu√© es Java?"), lo env√≠as a una API de IA, y obtienes una respuesta inteligente de vuelta. Todo esto funcionando de forma concurrente, es decir, puede manejar muchas peticiones al mismo tiempo sin problemas.

## Caracter√≠sticas principales

- ‚úÖ **API REST simple**: Solo env√≠as un POST con tu texto y recibes la respuesta
- ‚úÖ **Soporte m√∫ltiple de IA**: Funciona con OpenAI o Groq API
- ‚úÖ **S√∫per r√°pido**: Usa goroutines de Go para manejar m√∫ltiples peticiones en paralelo
- ‚úÖ **Confiable**: Manejo de errores, timeouts, y cierre seguro del servidor
- ‚úÖ **F√°cil de usar**: Health check para verificar que todo funciona
- ‚úÖ **Opci√≥n gratuita**: Groq API es completamente gratuita para pruebas

## ¬øQu√© necesito para empezar?

**Requisitos b√°sicos:**
- Go 1.21 o superior instalado
- Una API key de Groq (gratuita) o OpenAI

**Opciones de API:**
- **Groq API**: Gratuita, solo necesitas crear una cuenta en https://console.groq.com/
- **OpenAI**: Requiere cr√©ditos (aunque suelen dar algunos gratis al registrarte)

## Primeros pasos

### 1. Clonar el proyecto

```bash
git clone <url-del-repositorio>
cd test-pulpoline-api
```

### 2. Instalar dependencias

```bash
go mod download
```

Esto descargar√° todas las librer√≠as que necesita el proyecto. Solo toma unos segundos.

### 3. Configurar el entorno

Tienes dos opciones, elige la que m√°s te convenga:

#### Opci√≥n A: Groq API (Gratuita - Recomendada) ‚≠ê

Perfecta para empezar, es completamente gratuita:

1. Ve a https://console.groq.com/ y crea una cuenta (es gratis, no requiere tarjeta)
2. Obt√©n tu API key desde el dashboard
3. Configura tu `.env`:

```env
AI_PROVIDER=groq
GROQ_API_KEY=tu_groq_api_key_aqui
SERVER_ADDR=:8080
```

#### Opci√≥n B: OpenAI (Si tienes cr√©ditos)

Si prefieres usar OpenAI (recuerda que tiene costo, aunque dan cr√©ditos iniciales):

```env
AI_PROVIDER=openai
OPENAI_API_KEY=tu_openai_key_aqui
SERVER_ADDR=:8080
```

**Tip:** Para usar variables de entorno directamente sin archivo `.env`:

```bash
# Windows PowerShell
$env:AI_PROVIDER="groq"
$env:GROQ_API_KEY="tu_key_aqui"
$env:SERVER_ADDR=":8080"

# Linux/Mac
export AI_PROVIDER=groq
export GROQ_API_KEY=tu_key_aqui
export SERVER_ADDR=:8080
```

## Ejecutar el servidor

Tienes dos formas de hacerlo:

### Opci√≥n 1: Ejecutar directamente (Recomendado para desarrollo)

```bash
go run ./cmd/api
```

### Opci√≥n 2: Compilar primero

```bash
go build -o test-pulpoline-api ./cmd/api
./test-pulpoline-api
```

Una vez ejecutado, ver√°s algo como:
```
Archivo .env cargado correctamente desde: .env
Configuraci√≥n cargada - Provider: groq, ServerAddr: :8080
Usando Groq API (gratuita)
Servidor iniciado en :8080
```

¬°Listo! Tu servidor est√° corriendo en `http://localhost:8080` üéâ

## C√≥mo usar la API

### Verificar que funciona (Health Check)

Primero, aseg√∫rate de que el servidor est√° vivo:

```bash
curl http://localhost:8080/health
```

Deber√≠as ver:
```json
{
  "status": "healthy",
  "service": "test-pulpoline-api"
}
```

### Procesar un texto

Ahora s√≠, env√≠a tu pregunta o texto a procesar:

```bash
curl -X POST http://localhost:8080/api/process \
  -H "Content-Type: application/json" \
  -d '{"text": "Explica qu√© es la programaci√≥n concurrente en Go"}'
```

**Respuesta exitosa:**
```json
{
  "id": "78ce2d49-3c73-4123-b65d-00a503f8113a",
  "text": "Explica qu√© es la programaci√≥n concurrente en Go",
  "response": "La programaci√≥n concurrente en Go...",
  "status": "success"
}
```

**Si algo sale mal:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "error": "error al procesar con IA: API key no est√° configurada",
  "status": "error"
}
```

## C√≥mo est√° organizado el c√≥digo

El proyecto sigue una estructura profesional tipo microservicio. Cada cosa tiene su lugar:

```
test-pulpoline-api/
‚îú‚îÄ‚îÄ cmd/api/              # üö™ La puerta de entrada - aqu√≠ empieza todo
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ config/          # ‚öôÔ∏è Configuraci√≥n y variables de entorno
‚îÇ   ‚îú‚îÄ‚îÄ handler/         # üì® Maneja las peticiones HTTP que llegan
‚îÇ   ‚îú‚îÄ‚îÄ service/         # üß† La l√≥gica de negocio - aqu√≠ se procesa todo
‚îÇ   ‚îú‚îÄ‚îÄ client/ai/       # ü§ñ Cliente para hablar con las APIs de IA
‚îÇ   ‚îî‚îÄ‚îÄ queue/           # üì¨ Sistema de colas para manejar concurrencia
‚îî‚îÄ‚îÄ pkg/errors/          # ‚ùå Errores personalizados
```

**En palabras simples:**
- `cmd/api` = El main, donde todo empieza
- `handler` = Recibe las peticiones del usuario
- `service` = Decide qu√© hacer con esas peticiones
- `client/ai` = Habla con OpenAI, Groq, etc.
- `queue` = Organiza las peticiones para no sobrecargarse

## C√≥mo funciona internamente

### El flujo completo

1. **Llega una petici√≥n** ‚Üí El handler la recibe y valida
2. **Se genera un ID √∫nico** ‚Üí Para rastrear cada petici√≥n
3. **Se encola o procesa directamente** ‚Üí Depende de cu√°ntas peticiones hay
4. **Se env√≠a a la IA** ‚Üí Tu texto va a OpenAI o Groq
5. **Se recibe la respuesta** ‚Üí La IA genera una respuesta
6. **Se devuelve al cliente** ‚Üí Tu recibe la respuesta en JSON

Todo esto pasa de forma **concurrente**, as√≠ que si llegan 10 peticiones al mismo tiempo, todas se procesan en paralelo sin bloquearse.

### Los "ingredientes" de la concurrencia

El sistema usa las herramientas de Go:
- **Goroutines**: Como trabajadores que procesan tareas en paralelo
- **Canales**: Como tubos de comunicaci√≥n entre los trabajadores
- **Context**: Para controlar timeouts y cancelaciones
- **WaitGroups**: Para coordinar que todos terminen correctamente

## Probar la aplicaci√≥n

### Prueba b√°sica

```bash
# Verificar que est√° vivo
curl http://localhost:8080/health

# Hacer una pregunta
curl -X POST http://localhost:8080/api/process \
  -H "Content-Type: application/json" \
  -d '{"text": "Hola, ¬øc√≥mo est√°s?"}'
```

### Probar concurrencia

¬øQuieres ver c√≥mo maneja m√∫ltiples peticiones a la vez? Prueba esto:

```bash
# En Linux/Mac
for i in {1..5}; do
  curl -X POST http://localhost:8080/api/process \
    -H "Content-Type: application/json" \
    -d "{\"text\": \"Petici√≥n n√∫mero $i\"}" &
done
wait
```

Esto enviar√° 5 peticiones al mismo tiempo. ¬°Ver√°s c√≥mo todas se procesan en paralelo!

## Configuraci√≥n avanzada

Si quieres ajustar cosas, puedes modificar estos valores en el c√≥digo:

- **Tama√±o de la cola**: En `main.go`, cambia `NewRequestQueue(10)` (10 = 10 peticiones en cola)
- **N√∫mero de workers**: En `queue.go`, cambia `workers: 5` (5 = 5 procesadores paralelos)
- **Timeout de peticiones**: En `handler.go`, cambia `30*time.Second` (30 segundos m√°ximo)
- **Modelo de IA**: En los clientes de IA, cambia el modelo seg√∫n lo que necesites

## Soluci√≥n de problemas comunes

### "No me toma las variables de entorno"

- Verifica que el archivo `.env` est√© en la ra√≠z del proyecto
- Aseg√∫rate de que no tenga espacios extra o caracteres raros
- Si usas Cursor/VSCode, reinicia el servidor despu√©s de cambiar el `.env`

### "La cola est√° llena"

El servidor est√° recibiendo muchas peticiones muy r√°pido. Puedes:
- Aumentar el tama√±o de la cola en `main.go`
- Esperar un momento y volver a intentar
- Revisar si hay alg√∫n proceso que est√© enviando demasiadas peticiones

### "El servidor no responde"

Verifica:
- ¬øEst√° corriendo? Busca el mensaje "Servidor iniciado en :8080"
- ¬øEl puerto est√° libre? Aseg√∫rate de que no haya otro proceso usando el puerto 8080
- ¬øHay errores en la consola? Revisa los logs que aparecen al iniciar

### "Error: API key no est√° configurada"

- Aseg√∫rate de tener la API key correcta en tu `.env`:
  - Para Groq: `GROQ_API_KEY=tu_key_aqui`
  - Para OpenAI: `OPENAI_API_KEY=tu_key_aqui`
- Verifica que `AI_PROVIDER` est√© configurado correctamente (`groq` o `openai`)
- Verifica que el `.env` est√© siendo cargado (deber√≠as ver un log al iniciar)

## Lo que hace especial este c√≥digo

- ‚úÖ **Bien organizado**: Cada cosa en su lugar, f√°cil de encontrar y modificar
- ‚úÖ **Manejo de errores**: Si algo falla, sabr√°s exactamente qu√© pas√≥
- ‚úÖ **Preparado para producci√≥n**: Cierre seguro, timeouts, validaciones
- ‚úÖ **F√°cil de extender**: Agregar nuevas funcionalidades es sencillo
- ‚úÖ **Documentado**: El c√≥digo explica qu√© hace cada cosa
- ‚úÖ **Seguro**: Usa canales y mutexes correctamente para evitar condiciones de carrera

## Ideas para mejorar (si quieres seguir trabajando en esto)

- [ ] Agregar autenticaci√≥n (API keys para proteger los endpoints)
- [ ] Implementar rate limiting (evitar abusos)
- [ ] Agregar m√©tricas (ver cu√°ntas peticiones se procesan, tiempos, etc.)
- [ ] Tests automatizados (para asegurar que todo funciona)
- [ ] Cache de respuestas (para no repetir las mismas peticiones)
- [ ] Documentaci√≥n OpenAPI/Swagger (para que otros sepan c√≥mo usar tu API)
- [ ] Soporte para m√°s modelos de IA

## Licencia

Este proyecto es parte de una prueba t√©cnica para Pulpoline.

## Autor

**Gabriel Alejandro Pina**  
Desarrollador FullStack
